{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec87891d-ba1e-48e4-8164-cf9fa6a0204a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\norar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\norar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\norar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe73a54a-634b-4ddd-bf6c-3e1c5dd81f83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 11314 rows and 5 columns.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('news_dataset.csv')\n",
    "print(f\"Dataset loaded with {df.shape[0]} rows and {df.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f28125-139e-486f-9937-3ec6a577be2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-null texts: 11096\n"
     ]
    }
   ],
   "source": [
    "texts = df['text'].dropna().tolist()\n",
    "print(f\"Number of non-null texts: {len(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad3b2f2-8826-4def-b883-d50c62a01df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69617c57-5cc7-47a6-8029-6db026d63420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Tokenize text\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    # Remove punctuation and stop words, and lemmatize the words\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af24110-ce7b-4471-94e5-fb7aafe67992",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preprocessed text: ['wondering', 'anyone', 'could', 'enlighten', 'car', 'saw', 'day', 'sport', 'car', 'looked']\n"
     ]
    }
   ],
   "source": [
    "processed_texts = [preprocess(text) for text in texts]\n",
    "print(f\"Sample preprocessed text: {processed_texts[0][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1273eb86-45ca-4227-a503-156a52fbe5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens before filtering: 55771\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(processed_texts)\n",
    "print(f\"Number of unique tokens before filtering: {len(dictionary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e9416ec-69d7-4f94-ba59-0259bfdf727a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens after filtering: 6229\n"
     ]
    }
   ],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5)\n",
    "print(f\"Number of unique tokens after filtering: {len(dictionary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73ae0f15-779a-4aa4-bc16-b31699243a23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample BOW for first document: [(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 4), (6, 1), (7, 1), (8, 1), (9, 1)]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in processed_texts]\n",
    "print(f\"Sample BOW for first document: {corpus[0][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79536878-36d6-42b4-bc26-5b65ab9d90d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA model training complete.\n"
     ]
    }
   ],
   "source": [
    "lda_model = models.LdaModel(corpus, num_topics=4, id2word=dictionary, passes=15)\n",
    "print(\"LDA model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54ea340c-c71d-4530-b49a-9a250b5fca94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.6057639447044583\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score = coherence_model_lda.get_coherence()\n",
    "print(f'Coherence Score: {coherence_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fea4a5f-904d-448a-981d-5c65ad2575c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.071*\"x\" + 0.060*\"q\" + 0.052*\"max\" + 0.034*\"g\" + 0.034*\"r\" + 0.029*\"p\" + 0.027*\"n\" + 0.019*\"k\" + 0.019*\"w\" + 0.018*\"v\"\n",
      "Topic 1: 0.011*\"would\" + 0.010*\"one\" + 0.009*\"get\" + 0.008*\"like\" + 0.007*\"know\" + 0.007*\"year\" + 0.006*\"time\" + 0.006*\"good\" + 0.006*\"game\" + 0.005*\"think\"\n",
      "Topic 2: 0.011*\"people\" + 0.010*\"would\" + 0.008*\"one\" + 0.006*\"think\" + 0.006*\"say\" + 0.005*\"god\" + 0.005*\"government\" + 0.005*\"u\" + 0.005*\"right\" + 0.005*\"know\"\n",
      "Topic 3: 0.013*\"key\" + 0.009*\"use\" + 0.009*\"system\" + 0.009*\"file\" + 0.007*\"program\" + 0.007*\"chip\" + 0.007*\"information\" + 0.006*\"db\" + 0.006*\"encryption\" + 0.005*\"available\"\n"
     ]
    }
   ],
   "source": [
    "topics = lda_model.print_topics(num_words=10)\n",
    "for idx, topic in topics:\n",
    "    print(f\"Topic {idx}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff058f-47d3-4aad-acc6-38842ed37d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nor Ardini Arwan - IS01082907\n",
    "# Alisa Nadia bt Ahmad Nizrasham - SW01081353\n",
    "\n",
    "# The coherence score of 0.606 for the LDA model indicates a moderately good level of topic coherence. \n",
    "# This suggests that the topics are fairly well-defined and understandable, though there is still potential for improvement. \n",
    "# For example, Topic 0 includes less meaningful words (\"x,\" \"q,\" \"max\"), whereas Topics 1, 2, and 3 contain more interpretable words related to themes like time, people, and systems. \n",
    "# Further fine-tuning of the model or preprocessing steps could enhance the coherence and interpretability of the topics.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
